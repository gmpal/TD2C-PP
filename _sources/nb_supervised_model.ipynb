{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b327439e",
   "metadata": {},
   "source": [
    "# The Supervised Model: From Descriptors to Probabilities\n",
    "\n",
    "Once we have converted pairs of variables into 63-dimensional feature vectors, the problem of causal discovery becomes a standard **Binary Classification** task.\n",
    "\n",
    "### Class Imbalance\n",
    "In any sparse graph (like a gene network), there are far more *non-causal* pairs than *causal* ones. A standard classifier would achieve high accuracy by simply predicting \"No Link\" every time.\n",
    "\n",
    "To solve this, we use a **Balanced Random Forest**, which undersamples the majority class (non-causal) in each bootstrap sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb4757f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 1. Load or Generate Data (Small scale for demonstration)\n",
    "# (In a real scenario, load 'descriptors_df_train.pkl')\n",
    "from td2c.data_generation.builder import TSBuilder\n",
    "from td2c.descriptors import DataLoader, D2C\n",
    "\n",
    "print(\"Generating dataset...\")\n",
    "builder = TSBuilder(n_variables=5, maxlags=2, observations_per_time_series=150, time_series_per_process=10, verbose=False)\n",
    "builder.build()\n",
    "loader = DataLoader(n_variables=5, maxlags=2)\n",
    "loader.from_tsbuilder(builder)\n",
    "\n",
    "d2c = D2C(loader.get_observations(), loader.get_dags(), n_variables=5, maxlags=2, n_jobs=1, full=True, dynamic=True, mb_estimator=\"ts\")\n",
    "d2c.initialize()\n",
    "df = d2c.get_descriptors_df()\n",
    "\n",
    "# 2. Split Data\n",
    "# Note: We should ideally split by 'graph_id' to avoid data leakage, \n",
    "# but for this simple demo, random split is sufficient.\n",
    "X = df.drop(columns=[\"graph_id\", \"edge_source\", \"edge_dest\", \"is_causal\"])\n",
    "y = df[\"is_causal\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 3. Train Model\n",
    "clf = BalancedRandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 4. Evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1ef82a",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "Does the model actually learn physics, or is it just memorizing noise? We can analyze the **Feature Importance** to see which descriptors matter most. \n",
    "\n",
    "Typically, we see a mix of:\n",
    "1.  **Error-based features** (e.g., `parcorr_errors`) capturing linear signals.\n",
    "2.  **Information-theoretic features** (e.g., `transfer_entropy`) capturing non-linear/asymmetric signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d2874a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Extract Feature Importances\n",
    "importances = clf.feature_importances_\n",
    "feature_names = X.columns\n",
    "feat_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "feat_df = feat_df.sort_values(by='Importance', ascending=False).head(15)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=feat_df, palette='viridis')\n",
    "plt.title(\"Top 15 Most Important Causal Descriptors\")\n",
    "plt.xlabel(\"Gini Importance\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
