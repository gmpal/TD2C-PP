{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4d1e17a",
   "metadata": {},
   "source": [
    "# Inference on Your Own Data\n",
    "\n",
    "This notebook allows you to apply the pre-trained TD2C model to your own time series data (e.g., CSV file).\n",
    "\n",
    "### Input Requirements\n",
    "1.  **Format:** A CSV file where **columns are variables** and **rows are time steps**.\n",
    "2.  **Stationarity:** The data should ideally be stationary. If not, consider differencing ($X_t - X_{t-1}$).\n",
    "3.  **Normalization:** The pipeline handles standardization internally.\n",
    "\n",
    "### 1. Load the Pre-trained Model\n",
    "In this example, we check if a saved model exists. If not, we train a robust one on synthetic data on-the-fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9a2459",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from td2c.data_generation.builder import TSBuilder\n",
    "from td2c.descriptors import D2C, DataLoader\n",
    "\n",
    "MODEL_PATH = \"pretrained_td2c.joblib\"\n",
    "\n",
    "def get_model():\n",
    "    if os.path.exists(MODEL_PATH):\n",
    "        print(f\"Loading model from {MODEL_PATH}...\")\n",
    "        return joblib.load(MODEL_PATH)\n",
    "    else:\n",
    "        print(\"Pre-trained model not found. Training a robust model now (this takes ~1 min)...\")\n",
    "        # Generate generic training data\n",
    "        builder = TSBuilder(n_variables=5, maxlags=2, observations_per_time_series=200, time_series_per_process=20, verbose=False)\n",
    "        builder.build()\n",
    "        loader = DataLoader(n_variables=5, maxlags=2)\n",
    "        loader.from_tsbuilder(builder)\n",
    "        \n",
    "        engine = D2C(loader.get_observations(), loader.get_dags(), n_variables=5, maxlags=2, n_jobs=-1, full=True, dynamic=True, mb_estimator=\"ts\")\n",
    "        engine.initialize()\n",
    "        df_train = engine.get_descriptors_df()\n",
    "        \n",
    "        X = df_train.drop(columns=[\"graph_id\", \"edge_source\", \"edge_dest\", \"is_causal\"])\n",
    "        y = df_train[\"is_causal\"]\n",
    "        \n",
    "        clf = BalancedRandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "        clf.fit(X, y)\n",
    "        \n",
    "        joblib.dump(clf, MODEL_PATH)\n",
    "        print(\"Model trained and saved.\")\n",
    "        return clf\n",
    "\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129c8d1d",
   "metadata": {},
   "source": [
    "### 2. Load Your Data\n",
    "Replace `'my_data.csv'` with your file path. For this demo, we create a dummy dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e144d91b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- User Input Section ---\n",
    "# df_user = pd.read_csv(\"my_data.csv\")\n",
    "\n",
    "# Creating dummy data for demonstration\n",
    "T = 100\n",
    "# A causes B with lag 1\n",
    "A = np.random.randn(T)\n",
    "B = np.roll(A, 1) + np.random.normal(0, 0.2, T)\n",
    "C = np.random.randn(T) # Noise\n",
    "df_user = pd.DataFrame({'Var_A': A, 'Var_B': B, 'Var_C': C}).iloc[1:] # Drop first row due to shift\n",
    "\n",
    "print(\"Data Preview:\")\n",
    "print(df_user.head())   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f555edbe",
   "metadata": {},
   "source": [
    "### 3. Run Inference\n",
    "We use the `D2CWrapper` to process the data and predict causal links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccda4bf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from td2c.benchmark import D2CWrapper\n",
    "\n",
    "# Convert to numpy array\n",
    "data_array = df_user.values\n",
    "n_vars = data_array.shape[1]\n",
    "var_names = df_user.columns.tolist()\n",
    "\n",
    "print(f\"Analyzing {n_vars} variables...\")\n",
    "\n",
    "# Run Inference\n",
    "wrapper = D2CWrapper(\n",
    "    ts_list=[data_array], \n",
    "    model=model,\n",
    "    n_variables=n_vars,\n",
    "    maxlags=2,\n",
    "    mb_estimator=\"ts\"\n",
    ")\n",
    "wrapper.run()\n",
    "\n",
    "# Extract Results\n",
    "results = wrapper.get_causal_dfs()[0]\n",
    "# Filter for significant links\n",
    "significant_links = results[results['probability'] > 0.5].copy()\n",
    "\n",
    "print(f\"\\nFound {len(significant_links)} causal links.\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccb3461",
   "metadata": {},
   "source": [
    "### 4. Visualize the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d4d696",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add nodes\n",
    "for name in var_names:\n",
    "    G.add_node(name)\n",
    "\n",
    "# Add edges\n",
    "for _, row in significant_links.iterrows():\n",
    "    # Map index to name\n",
    "    # The output 'from'/'to' are indices in the lagged flattened array\n",
    "    # We need to map them back to variable names\n",
    "    # Simplified mapping for visualization:\n",
    "    \n",
    "    # TD2C output format: 0..N-1 are variables at t\n",
    "    # N..2N-1 are variables at t-1, etc.\n",
    "    \n",
    "    source_idx = int(row['from'])\n",
    "    target_idx = int(row['to'])\n",
    "    \n",
    "    # Determine Lag\n",
    "    lag = source_idx // n_vars\n",
    "    actual_source_var_idx = source_idx % n_vars\n",
    "    \n",
    "    source_name = var_names[actual_source_var_idx]\n",
    "    target_name = var_names[target_idx]\n",
    "    \n",
    "    # Add edge with lag info\n",
    "    G.add_edge(source_name, target_name, lag=lag, weight=row['probability'])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "nx.draw(G, pos, with_labels=True, node_color='lightblue', node_size=2000, font_size=12, arrowsize=20)\n",
    "edge_labels = nx.get_edge_attributes(G, 'lag')\n",
    "edge_labels = {k: f\"Lag {v}\" for k, v in edge_labels.items()}\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
    "plt.title(\"Inferred Causal Graph\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
