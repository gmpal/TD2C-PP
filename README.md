# Causal Discovery in Multivariate Time Series through Mutual Information Featurization

[![Python 3.11](https://img.shields.io/badge/python-3.11-blue.svg)](https://www.python.org/downloads/release/python-3110/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Paper](https://img.shields.io/badge/paper-arXiv-red.svg)](https://arxiv.org/abs/2508.01848)

**Reproducibility package for:**
> Gian Marco Paldino, Gianluca Bontempi. *Causal Discovery in Multivariate Time Series through Mutual Information Featurization*. International Journal of Forecasting, 2025.

---

## Reproducibility Package Information

- **Date assembled:** January 2025
- **Authors:** Gian Marco Paldino (`gian.marco.paldino@ulb.be`), Gianluca Bontempi (`gianluca.bontempi@ulb.be`)
- **Affiliation:** Machine Learning Group, Computer Science Department, Université Libre de Bruxelles (ULB), Brussels, Belgium
- **License:** MIT

---

## Repository Structure

```
.
├── src/                        # Core source code for the TD2C framework
│   └── td2c/
│       ├── benchmark/          # TD2C and competitor method implementations
│       │   └── utils.py        # draw_cd_diagram and evaluation utilities
│       ├── data_generation/    # Synthetic NAR time series generation
│       └── descriptors/        # D2C descriptor computation (core of TD2C)
│
├── reproduce/
│   ├── py_scripts/             # Numbered Python scripts — one per pipeline step
│   │   ├── pipeline.py         # Master orchestrator: runs all steps in order
│   │   ├── 00.py               # Path counting exploration (not in main pipeline)
│   │   ├── 01.py               # Step 1: synthetic data generation
│   │   ├── 02.py               # Step 2: descriptor computation  [HEAVY]
│   │   ├── 03.py               # Step 3: threshold selection via LOGO-CV
│   │   ├── 04.py               # Step 4: full benchmark execution  [HEAVY]
│   │   ├── 05.py               # Step 5: synthetic test set analysis → Tables 2 & 3
│   │   ├── 06.py               # Step 6: realistic benchmark analysis → Table 4, Figure 1
│   │   ├── 07.py               # Step 7: CD diagrams → Figures 2 & 3
│   │   ├── 08.py               # Step 8: scalability/runtime benchmark → Table 5
│   │   └── 09.py               # Step 9: feature importance → Table 6
│   └── notebooks/              # Jupyter notebooks (exploratory, same pipeline logic)
│
├── data/                       # All datasets and cached results (see below)
│   ├── observations/           # [INTERMEDIARY] Synthetic time series, generated by 01.py
│   ├── descriptors/            # [INTERMEDIARY] Pre-computed TD2C descriptors, from 02.py
│   ├── before_d2c/             # [INTERMEDIARY] Cached competitor results, from 04.py
│   ├── causal_dfs/             # [FINAL] Full benchmark results for all methods, from 04.py
│   └── realistic/              # Real-world datasets (DREAM3, NetSim) — pre-processed
│       ├── dream3/             # DREAM3 benchmark (10-node and 50-node variants)
│       └── netsym/             # NetSim benchmark (5-node and 10-node variants)
│
├── knncmi/                     # Submodule: k-NN conditional mutual information estimator
├── requirements.txt            # All Python dependencies with versions
└── README.md                   # This file
```

---

## Computing Environment

| Component | Full Experiments (cluster) | Light Reproduction (laptop) |
|---|---|---|
| **OS** | Linux | Any (tested on Windows 11) |
| **CPU** | 40-core cluster node | Intel Core i7 |
| **RAM** | 377 GB | 32 GB |
| **Python** | 3.11.10 | 3.11.10 |
| **`--n_jobs`** | 40 | 4 |

**Language:** Python 3.11
**Package manager:** conda (miniforge recommended)
**Key dependencies** (see `requirements.txt` for full list with pinned versions):

| Package | Version | Purpose |
|---|---|---|
| `numpy` | 1.26.4 | Numerical computation |
| `pandas` | 2.2.3 | Data manipulation |
| `scikit-learn` | 1.6.1 | Machine learning metrics and classifiers |
| `imbalanced-learn` | 0.11.0 | `BalancedRandomForestClassifier` |
| `tigramite` | 5.2.10.1 | PCMCI implementation |
| `lingam` | 1.12.2 | VARLiNGAM implementation |
| `dcor` | 0.6 | Distance correlation (used by tigramite/GPDC) |
| `matplotlib` | 3.9.2 | Plotting |
| `seaborn` | 0.13.2 | Statistical visualisation |
| `scipy` | 1.13.1 | Statistical tests (Wilcoxon, Friedman) |
| `networkx` | 3.3 | Graph utilities |

---

## Installation

### 1. Create conda environment

```bash
conda create -n td2c python=3.11 -y
conda activate td2c
```

### 2. Install knncmi (k-NN conditional MI estimator)

```bash
git clone https://github.com/omesner/knncmi.git
cd knncmi
pip install .
cd ..
```

### 3. Clone this repository and install dependencies

```bash
git clone https://github.com/gmpal/IJF-TD2C.git
cd IJF-TD2C
pip install -r requirements.txt
```

### 4. Download the data folder

The `data/` directory (~500 MB) contains all datasets, pre-computed descriptors, and cached results. It is stored separately from the repository due to its size.

**Download link:** [data.zip (Google Drive)](https://drive.google.com/file/d/1z8cHkUTe7TlvWwqBlpoEsukWaSsvFC26/view?usp=sharing)

Via shell:
```bash
pip install gdown
gdown 1z8cHkUTe7TlvWwqBlpoEsukWaSsvFC26
python3 -m zipfile -e data.zip .
```

Place the resulting `data/` folder in the root of the repository.

---

## Data Description

### Synthetic data
Generated programmatically by `01.py` using NAR (Nonlinear AutoRegressive) processes. Nine processes (IDs: 1, 3, 5, 7, 9, 11, 13, 15, 19) with three noise distributions (Gaussian, Uniform, Laplace). No external source required.

- **Training set:** `data/observations/training_data_{gaussian,uniform,laplace}.pkl` — 120 time series per process per noise type (3240 total)
- **Test set:** `data/observations/testing_data_{gaussian,uniform,laplace}.pkl` — 40 time series per process per noise type (1080 total)

### Realistic data (DREAM3 and NetSim)
Pre-processed versions are included directly in the repository under `data/realistic/`. No registration, cost, or restricted access. Both datasets are publicly available:

- **DREAM3:** In-silico gene regulatory networks. Original source: [DREAM3 challenge (Synapse)](https://www.synapse.org/#!Synapse:syn2853594). Pre-processing notebook: `data/realistic/dream3/dream3.ipynb`
- **NetSim:** Simulated fMRI time series with known connectivity. Original source: [Smith et al. (2011), NeuroImage](https://www.sciencedirect.com/science/article/pii/S1053811910011602). Pre-processing notebook: `data/realistic/netsym/netsym.ipynb`

### Intermediary data files
The following files are intermediary (expensive to recompute) and are included in `data.zip` to allow skipping heavy steps:

| File(s) | Generated by | Description |
|---|---|---|
| `data/observations/*.pkl` | `01.py` | Raw synthetic time series |
| `data/descriptors/*.pkl` | `02.py` | TD2C descriptor matrices (hours to compute) |
| `data/before_d2c/*.pkl` | `04.py` | Competitor method predictions (hours to compute) |
| `data/causal_dfs/*.pkl` | `04.py` | Final combined results for all methods |

---

## Reproducing the Results

All scripts must be run from the `reproduce/py_scripts/` directory:

```bash
cd reproduce/py_scripts
```

### Quick reproduction (~5 minutes, laptop)

Use pre-computed intermediary data to skip the two heavy steps and regenerate all tables and figures:

```bash
python pipeline.py --n_jobs 4 --skip_data --skip_descriptors --skip_benchmark
```

This runs steps 3, 5, 6, 7, and 9 — producing all paper tables and figures.

### Full reproduction from scratch (cluster, ~2–3 days)

```bash
python pipeline.py --n_jobs 40
```

### Skip flags explained

| Flag | Skips | Requires |
|---|---|---|
| `--skip_data` | Step 01 (data generation) | `data/observations/*.pkl` present |
| `--skip_descriptors` | Step 02 (descriptor computation) | `data/descriptors/*.pkl` present |
| `--skip_benchmark` | Step 04 (benchmark execution) | `data/before_d2c/*.pkl` and `data/causal_dfs/*.pkl` present |

All three are satisfied by the provided `data.zip`.

### Running individual steps

```bash
python 03.py --n_jobs 4   # threshold selection
python 05.py              # synthetic analysis
python 06.py              # realistic analysis
python 07.py              # CD diagrams
python 08.py --n_jobs 4   # scalability benchmark (standalone, not in pipeline)
python 09.py --n_jobs 4   # feature importance
```

---

## Paper Tables and Figures — Output Mapping

| Paper item | Script | Output file |
|---|---|---|
| **Table 1** — Threshold selection metrics | `03.py` | Console output |
| **Table 2** — Synthetic overall results | `05.py` | `TEST_analysis/tables/overall_macro_summary.csv` |
| **Table 3** — Per-process results | `05.py` | `TEST_analysis/tables/macro_process_*.csv` |
| **Table 4** — Realistic benchmark results | `06.py` | `REAL_analysis/tables/summary_macro_{NETSIM_5,NETSIM_10,DREAM3_10,DREAM3_50}.csv` |
| **Table 5** — Runtime per method | `08.py` | `data/benchmark_times_by_nvars.csv` |
| **Table 6** — Feature importance | `09.py` | Console output |
| **Figure 1** — F1-score boxplot (realistic) | `06.py` | `REAL_analysis/figures/summary_boxplot_all_datasets_F1-Score.png` |
| **Figure 2a** — CD diagram (Precision) | `07.py` | `CD_PLOTS/cd_TEST_precision.png` |
| **Figure 2b** — CD diagram (Recall) | `07.py` | `CD_PLOTS/cd_TEST_recall.png` |
| **Figure 3a** — CD diagram (F1) | `07.py` | `CD_PLOTS/cd_TEST_f1.png` |
| **Figure 3b** — CD diagram (Accuracy) | `07.py` | `CD_PLOTS/cd_TEST_accuracy.png` |
| **Figure 3c** — CD diagram (Balanced Accuracy) | `07.py` | `CD_PLOTS/cd_TEST_balanced_accuracy.png` |

---

## Expected Runtimes

| Step | Script | Laptop (4 cores) | Cluster (40 cores) |
|---|---|---|---|
| 01 — Data generation | `01.py` | ~10 min | ~2 min |
| 02 — Descriptor computation | `02.py` | days | ~12 hours |
| 03 — Threshold selection | `03.py` | ~1 min | ~30 sec |
| 04 — Benchmark execution | `04.py` | days | ~36 hours |
| 05 — Synthetic analysis | `05.py` | ~2 min | ~2 min |
| 06 — Realistic analysis | `06.py` | ~2 min | ~2 min |
| 07 — CD diagrams | `07.py` | ~1 min | ~1 min |
| 08 — Scalability benchmark | `08.py` | ~30 min | ~5 min |
| 09 — Feature importance | `09.py` | ~1 min | ~1 min |
| **Total (with skips)** | | **~5 min** | **~5 min** |
| **Total (from scratch)** | | **days** | **~2–3 days** |

Steps 02 and 04 are the bottleneck. All intermediary outputs are provided in `data.zip` to bypass them.

---

## Citation

```bibtex
@article{paldino2025causal,
  title={Causal Discovery in Multivariate Time Series through Mutual Information Featurization},
  author={Paldino, Gian Marco and Bontempi, Gianluca},
  journal={International Journal of Forecasting},
  year={2025}
}
```

## Acknowledgements

Gian Marco Paldino and Gianluca Bontempi are supported by the Service Public de Wallonie Recherche under grant nr 2010235–ARIAC by DigitalWallonia4.ai. Computational resources have been provided by the Consortium des Équipements de Calcul Intensif (CÉCI), funded by the Fonds de la Recherche Scientifique de Belgique (F.R.S.-FNRS) under Grant No. 2.5020.11 and by the Walloon Region.
